\documentclass{article}
\usepackage{fullpage}
\usepackage{listings}
\usepackage{color}
\usepackage{mathtools}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=R,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\usepackage{amssymb} % for \smallsetminus
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\title{Assignment 1: CS 224d (Jerrick Hoang)}
\date{Due: Wednesday }
\renewcommand{\baselinestretch}{1.5}
\large
\begin{document}

\maketitle

\begin{enumerate}
\item Softmax is translational invariant
$\rho(\pmb{x} + c)_j = \frac{\exp(x_j + c)}{\sum_{k=1}^{\pmb{K}} \exp(x_k + c)} = \frac{\exp(x_j)\exp(c)}{\exp(c)\sum_{k=1}^{\pmb{K}}\exp(x_k)} = \frac{\exp(x_j)}{\sum_{k=1}^{\pmb{K}}\exp(x_k)} = \rho(\pmb{x})$

\item 
\begin{enumerate}
\item 
Let $\rho(\pmb{x}) = \frac{1}{1 + e^{-\pmb{x}}}$
Then $\frac{\partial \rho}{\partial \pmb{x}} = \frac{-1}{(1+e^{-\pmb{x}})^2} \frac{d (1 + e^{-\pmb{x}})}{d \pmb{x}} = \frac{e^{-\pmb{x}}}{(1 + e^{-\pmb{x}})^2} = (1-\rho(\pmb{x})\rho(\pmb{x})$
\item Let $h(z)_j = \frac{e^{z_j}}{\sum e^{z_i}}$. Let's derive $\frac{\partial h(z)_j}{\partial z_i}$. When $i = j$, must find $\frac{\partial h(z)_j}{\partial z_j} = \frac{\partial}{\partial z_j} \frac{e^{z_j}}{\sum e^{z_i}} = \frac{e^{z_j}(\sum e^{z_i}) - e^{2z_j}}{(\sum e^{z_i})^2} = h(z)_j ( 1 - h(z)_j)$. When $i \neq j$, $\frac{\partial h(z)_j}{\partial z_i} = \frac{\partial}{\partial z_i} \frac{e^{z_j}}{\sum e^{z_i}} = \frac{-e^{z_j}e^{z_i}}{(\sum e^{z_i})^2} = -h(z)_ih(z)_j$. 

Now, $\frac{\partial CE(y, \hat{y})}{\partial \theta_j} = - \sum_i y_i \frac{\partial}{\partial \theta_j} \log h(\theta)_i = - \sum_i \frac{y_i}{h(\theta)_i} \frac{\partial}{\partial \theta_j} h(\theta)_i = - \sum_{i\neq j} \frac{y_i}{h(\theta)_i}h(\theta)_ih(\theta)_j - (h(\theta)_j ( 1 - h(\theta)_j)) = - h(\theta)_j (\sum_{i\neq j} y_i + 1 - h(\theta)_j)$ 

\item $\frac{\partial \hat{y}}{\partial x} = \frac{\partial \hat{y}}{\partial h} \frac{dh}{dx} = $

\item $D_x * H + H * D_y$ weights 
\end{enumerate}

\item 
\begin{enumerate}
\item $CE = - \sum_i y_i log(\frac{\exp(\hat{r}^{\intercal}w_i)}{\sum_j exp(\hat{r}^{\intercal}w_j}))$. So, $\frac{\partial CE}{\partial \hat{r}} = -\sum_i y_i \frac{\partial}{\partial \hat{r}} \log \frac{e^{\hat{r}^{\intercal}w_i}}{\sum_j e^{\hat{r}^{\intercal}w_j}} = -\sum_i y_i(\frac{\partial}{\partial \hat{r}}\log e^{\hat{r}^{\intercal}w_i} - \frac{\partial}{\partial \hat{r}} log(\sum_j e^{\hat{r}^{\intercal}w_j})) = - \sum y_i (w_i - \frac{w_je^{\hat{r}^{\intercal}w_j}}{\sum_j e^{\hat{r}^{\intercal}w_j}}) = - \sum_i y_i (w_i - \sum_j w_j Pr(word_j | \hat{r}, w))$

\item $CE = - \sum_i y_i log(\frac{\exp(\hat{r}^{\intercal}w_i)}{\sum_j exp(\hat{r}^{\intercal}w_j}))$. So, $\frac{\partial CE}{\partial w_k} = -\sum_i y_i \frac{\partial}{\partial w_k} \log \frac{e^{\hat{r}^{\intercal}w_i}}{\sum_j e^{\hat{r}^{\intercal}w_j}} = -\sum_i y_i(\frac{\partial}{\partial w_k}\log e^{\hat{r}^{\intercal}w_i} - \frac{\partial}{\partial w_k} log(\sum_j e^{\hat{r}^{\intercal}w_j})) = - \sum y_i (1_{k=i}\hat{r} - \frac{\hat{r}e^{\hat{r}^{\intercal}w_k}}{\sum_j e^{\hat{r}^{\intercal}w_j}}) = - \sum_i y_i \hat{r}(1_{k=i} - Pr(word_k | \hat{r}, w))$
\end{enumerate}
\end{enumerate}
\end{document}
